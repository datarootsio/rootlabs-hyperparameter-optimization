{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QeUp1cABgBu"
      },
      "source": [
        "**Set-up**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rA7Jg7zB1tzI"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install optuna\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBMUFyRTBCyR"
      },
      "outputs": [],
      "source": [
        "# Import Packages\n",
        "## for data and preprocessing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "## for model fitting\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "import sklearn.metrics as metric\n",
        "\n",
        "## for hyperparameter optimization\n",
        "import optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lq307ThH1cix"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('/content/sample_data/california_housing_train.csv')\n",
        "test = pd.read_csv('/content/sample_data/california_housing_test.csv')\n",
        "\n",
        "names = train.columns\n",
        "\n",
        "scaler = StandardScaler()\n",
        "train = pd.DataFrame(scaler.fit_transform(train),columns=names)\n",
        "test = pd.DataFrame(scaler.transform(test), columns=names)\n",
        "\n",
        "\n",
        "X_train = train.drop(['median_house_value'],axis=1)\n",
        "X_test  = test.drop(['median_house_value'],axis=1)\n",
        "y_train = train.median_house_value\n",
        "y_test  = test.median_house_value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbUodoqRQiLJ"
      },
      "source": [
        "# **OPTUNA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPWbpIQzWQYR"
      },
      "source": [
        "## **General Overview**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8NPYlPKfrpM"
      },
      "source": [
        "Optuna optimizes any objective function. This objective function takes a set of arguments (e.g., hyperparameters) and returns a single value (e.g., validation score).  \n",
        "\n",
        "In Optuna, we create a study. A Study consists of a set of Trials. A study is defined by the objective function and the hyperparameter space. \n",
        "Each trial is, thus, a single selection from the hyperparameter space for which we evaluate the objective function.\n",
        "\n",
        "The optimization algorithm helps in intelligently picking the next trial to evaluate in a smart(er) way, until we find the optimal value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-cncUm2QlWI"
      },
      "source": [
        "In practice, every hyperparameter optimization exercise consist of 4 steps:\n",
        "\n",
        "* define a function which **trains a model** and **returns the validation score**\n",
        "\n",
        "* define the **hyperparameter space** through which the optimization algorithm can search (trials are instances/realizations of this space)\n",
        "\n",
        "* create a **study**, which describes the optimization exercise: \n",
        "    * *Direction* : \n",
        "        * minimize: for (Root) Mean Squared Errors, minus-log-likelihood, ...\n",
        "        * maximize: r2_score, auc, accuracy, precision, recall, f1_score, ...\n",
        "    * *Sampler* : the chosen optimization technique **(Optimization)**\n",
        "    * *Pruner* : early stopping of unpromising trials **(Steroids)**\n",
        "\n",
        "* **optimize** the study using different trials in a smart way **(worker function)**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_hxYNpUzCmnj"
      },
      "outputs": [],
      "source": [
        "%%script false --no-raise-error\n",
        "# STEP 1 #\n",
        "#========#\n",
        "\n",
        "def train_evaluate(params):\n",
        "    train_data = lgb.Dataset(X_train, label=y_train)\n",
        "    test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
        "    # Train a Model\n",
        "    model = lgb.train(params, train_data,\n",
        "                      num_boost_round=params['NUM_BOOST_ROUND'],\n",
        "                      early_stopping_rounds=params['EARLY_STOPPING_ROUNDS'],\n",
        "                      valid_sets=[test_data],\n",
        "                      valid_names=['valid'],\n",
        "                      )\n",
        "    # Evaluate the model\n",
        "    preds = model.predict(test_data,num_iteration=model.best_iteration)\n",
        "    truth = test_data.get_label()\n",
        "    score = metric.mean_squared_error(truth, preds, squared=False)\n",
        "      \n",
        "    #score = model.best_score['valid']['rmse']\n",
        "    # Return the validation score\n",
        "    return score\n",
        "\n",
        "# STEP 2 #\n",
        "#========#\n",
        "\n",
        "def objective(trial):\n",
        "    # Define the Hyper-parameter Space\n",
        "    params = {'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.5),\n",
        "              'max_depth': trial.suggest_int('max_depth', 1, 30, 1),\n",
        "              'num_leaves': trial.suggest_int('num_leaves', 2, 100),\n",
        "              'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 100),\n",
        "              'feature_fraction': trial.suggest_uniform('feature_fraction', 0.1, 1.0),\n",
        "              'subsample': trial.suggest_discrete_uniform('subsample', 0.1, 1.0,.1),\n",
        "              'colsample_by_tree': 1,\n",
        "              'lambda_l1': trial.suggest_float('lambda_l1', 0, 10),\n",
        "              'lambda_l2': trial.suggest_float('lambda_l2', 0, 10),\n",
        "              'NUM_BOOST_ROUND': 200,\n",
        "              'EARLY_STOPPING_ROUNDS': 20,\n",
        "              'objective': 'rmse',\n",
        "              }\n",
        "    # Train the model and return the validation score\n",
        "    score = train_evaluate(params)\n",
        "    # Return the validation score\n",
        "    return score\n",
        "\n",
        "# STEP 3 #\n",
        "#========#\n",
        "\n",
        "study = optuna.create_study(\n",
        "    direction = 'minimize',\n",
        "    sampler = optuna.samplers.RandomSampler(),      # GridSampler, RandomSampler, CmaEsSampler, TPESampler (default), ...\n",
        "    pruner = optuna.pruners.NopPruner()             # NopPruner, MedianPruner (default), SuccessiveHalvingPruner, HyperbandPruner,...\n",
        "    )\n",
        "\n",
        "# STEP 4 #\n",
        "#========#\n",
        "\n",
        "study.optimize(objective, n_trials=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sxSQuoTiJ4AC"
      },
      "outputs": [],
      "source": [
        "N_TRIALS = 200"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLDo29BxV6uP"
      },
      "source": [
        "## **Grid Search**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-M3qPkBmJCVh",
        "outputId": "5c56114a-287b-4f09-e83e-43fb75db7da9"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "%%capture\n",
        "\n",
        "def train_evaluate(params):\n",
        "    #X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
        "\n",
        "    train_data = lgb.Dataset(X_train, label=y_train)\n",
        "    test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
        "\n",
        "    model = lgb.train(params, train_data,\n",
        "                      num_boost_round=params['NUM_BOOST_ROUND'],\n",
        "                      early_stopping_rounds=params['EARLY_STOPPING_ROUNDS'],\n",
        "                      valid_sets=[test_data],\n",
        "                      valid_names=['valid'],\n",
        "                      verbose_eval=params['verbose']\n",
        "                      )\n",
        "    preds = model.predict(X_test,num_iteration=model.best_iteration)\n",
        "    truth = test_data.get_label()\n",
        "    score = metric.mean_squared_error(truth, preds, squared=False)\n",
        "    return score\n",
        "\n",
        "def objective(trial):\n",
        "    # Define the Hyper-parameter Space\n",
        "    params = {'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.5),\n",
        "              'max_depth': trial.suggest_int('max_depth', 1, 50),\n",
        "              'num_leaves': trial.suggest_int('num_leaves', 2, 200),\n",
        "              'NUM_BOOST_ROUND': 200,\n",
        "              'EARLY_STOPPING_ROUNDS': 20,\n",
        "              'objective': 'rmse',\n",
        "              'verbose': -1,\n",
        "              }\n",
        "    \n",
        "    score = train_evaluate(params)\n",
        "    return score\n",
        "\n",
        "search_space = {'learning_rate': [0.01, 0.10, 0.50],\n",
        "              'max_depth': [1, 10, 20, 30],\n",
        "              'num_leaves': [2, 10, 20, 100]}\n",
        "study1 = optuna.create_study(\n",
        "    direction='minimize',\n",
        "    sampler=optuna.samplers.GridSampler(search_space)\n",
        "    )\n",
        "study1.optimize(objective, n_trials=N_TRIALS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Si3TBSQPLA2",
        "outputId": "0c67db2b-7479-478f-87a5-fb9d9f2eb9b4"
      },
      "outputs": [],
      "source": [
        "gridsearch = {'score': study1.best_value, 'params': study1.best_params}\n",
        "print(gridsearch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sn-ozVvUXKY-"
      },
      "source": [
        "## **Random Search**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dc6wSh7LXV1p",
        "outputId": "0ff9959c-671b-4464-ffb7-0a0985dc370f"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "%%capture\n",
        "def train_evaluate(params):\n",
        "    train_data = lgb.Dataset(X_train, label=y_train)\n",
        "    test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
        "    # Train a Model\n",
        "    model = lgb.train(params, train_data,\n",
        "                      num_boost_round=params['NUM_BOOST_ROUND'],\n",
        "                      early_stopping_rounds=params['EARLY_STOPPING_ROUNDS'],\n",
        "                      valid_sets=[test_data],\n",
        "                      valid_names=['valid'],\n",
        "                      )\n",
        "    # Evaluate the model \n",
        "    preds = model.predict(X_test,num_iteration=model.best_iteration)\n",
        "    truth = test_data.get_label()\n",
        "    score = metric.mean_squared_error(truth, preds, squared=False)\n",
        "    # Return the validation score\n",
        "    return score\n",
        "\n",
        "def objective(trial):\n",
        "    # Define the Hyper-parameter Space\n",
        "    params = {'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.5),\n",
        "              'max_depth': trial.suggest_int('max_depth', 1, 50),\n",
        "              'num_leaves': trial.suggest_int('num_leaves', 2, 200),\n",
        "              'feature_fraction': trial.suggest_uniform('feature_fraction', 0.1, 1.0),\n",
        "              'subsample': trial.suggest_discrete_uniform('subsample', 0.1, 1.0, .1),\n",
        "              'colsample_by_tree': 1,\n",
        "              'lambda_l1': trial.suggest_float('lambda_l1', 0, 10),\n",
        "              'lambda_l2': trial.suggest_float('lambda_l2', 0, 10),\n",
        "              'bagging_fraction':trial.suggest_uniform('bagging_fraction', 0, 1),\n",
        "              'bagging_freq':trial.suggest_int('bagging_freq', 0, 10),\n",
        "              'NUM_BOOST_ROUND': 200,\n",
        "              'EARLY_STOPPING_ROUNDS': 20,\n",
        "              'objective': 'rmse',\n",
        "              }\n",
        "    # Train the model and return the validation score\n",
        "    score = train_evaluate(params)\n",
        "\n",
        "    # Return the validation score\n",
        "    return score\n",
        "\n",
        "study2 = optuna.create_study(\n",
        "    direction = 'minimize',\n",
        "    sampler = optuna.samplers.RandomSampler()\n",
        "    )\n",
        "\n",
        "study2.optimize(objective, n_trials=N_TRIALS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqGKn8p4aSxZ",
        "outputId": "d6141829-ede7-42f6-feea-c98f8ab4c9f1"
      },
      "outputs": [],
      "source": [
        "randomsearch = {'score': study2.best_value, 'params': study2.best_params}\n",
        "print(randomsearch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrAr9OUvJYJl"
      },
      "source": [
        "## **CMAES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wv1aInVeJV9Y",
        "outputId": "3918ff77-7525-4ed5-9936-729eb3d943d0"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "%%capture\n",
        "def train_evaluate(params):\n",
        "    train_data = lgb.Dataset(X_train, label=y_train)\n",
        "    test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
        "    # Train a Model\n",
        "    model = lgb.train(params, train_data,\n",
        "                      num_boost_round=params['NUM_BOOST_ROUND'],\n",
        "                      early_stopping_rounds=params['EARLY_STOPPING_ROUNDS'],\n",
        "                      valid_sets=[test_data],\n",
        "                      valid_names=['valid'],\n",
        "                      )\n",
        "    # Evaluate the model \n",
        "    preds = model.predict(X_test,num_iteration=model.best_iteration)\n",
        "    truth = test_data.get_label()\n",
        "    score = metric.mean_squared_error(truth, preds, squared=False)\n",
        "    # Return the validation score\n",
        "    return score\n",
        "\n",
        "def objective(trial):\n",
        "    # Define the Hyper-parameter Space\n",
        "    params = {'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.5),\n",
        "              'max_depth': trial.suggest_int('max_depth', 1, 50),\n",
        "              'num_leaves': trial.suggest_int('num_leaves', 2, 200),\n",
        "              'feature_fraction': trial.suggest_uniform('feature_fraction', 0.1, 1.0),\n",
        "              'subsample': trial.suggest_discrete_uniform('subsample', 0.1, 1.0, .1),\n",
        "              'colsample_by_tree': 1,\n",
        "              'lambda_l1': trial.suggest_float('lambda_l1', 0, 10),\n",
        "              'lambda_l2': trial.suggest_float('lambda_l2', 0, 10),\n",
        "              'bagging_fraction':trial.suggest_uniform('bagging_fraction', 0, 1),\n",
        "              'bagging_freq':trial.suggest_int('bagging_freq',0,10),\n",
        "              'NUM_BOOST_ROUND': 200,\n",
        "              'EARLY_STOPPING_ROUNDS': 20,\n",
        "              'objective': 'rmse',\n",
        "              }\n",
        "    # Train the model and return the validation score\n",
        "    score = train_evaluate(params)\n",
        "    \n",
        "    #Check Pruning\n",
        "    trial.report(score,200)\n",
        "    if trial.should_prune():\n",
        "      raise optuna.TrialPruned()\n",
        "    \n",
        "    # Return the validation score\n",
        "    return score\n",
        "\n",
        "study3 = optuna.create_study(\n",
        "    direction = 'minimize',\n",
        "    sampler = optuna.samplers.CmaEsSampler()\n",
        "    )\n",
        "\n",
        "study3.optimize(objective, n_trials=N_TRIALS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggS0cFflJixW",
        "outputId": "889e8c19-1a72-458c-d55b-be1063aab04d"
      },
      "outputs": [],
      "source": [
        "cmaessearch = {'score': study3.best_value, 'params': study3.best_params}\n",
        "print(cmaessearch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGCET5ZNaTol"
      },
      "source": [
        "## **BOHB**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLlozjVlbKfh",
        "outputId": "e7ec100d-62de-40e3-bdc6-ced310ae3afb"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "%%capture\n",
        "def train_evaluate(params):\n",
        "    train_data = lgb.Dataset(X_train, label=y_train)\n",
        "    test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
        "    # Train a Model\n",
        "    model = lgb.train(params, train_data,\n",
        "                      num_boost_round=params['NUM_BOOST_ROUND'],\n",
        "                      early_stopping_rounds=params['EARLY_STOPPING_ROUNDS'],\n",
        "                      valid_sets=[test_data],\n",
        "                      valid_names=['valid'],\n",
        "                      )\n",
        "    # Evaluate the model \n",
        "    preds = model.predict(X_test,num_iteration=model.best_iteration)\n",
        "    truth = test_data.get_label()\n",
        "    score = metric.mean_squared_error(truth, preds, squared=False)\n",
        "    # Return the validation score\n",
        "    return score\n",
        "\n",
        "def objective(trial):\n",
        "    # Define the Hyper-parameter Space\n",
        "    params = {'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.5),\n",
        "              'max_depth': trial.suggest_int('max_depth', 1, 50),\n",
        "              'num_leaves': trial.suggest_int('num_leaves', 2, 200),\n",
        "              'feature_fraction': trial.suggest_uniform('feature_fraction', 0.1, 1.0),\n",
        "              'subsample': trial.suggest_discrete_uniform('subsample', 0.1, 1.0, .1),\n",
        "              'colsample_by_tree': 1,\n",
        "              'lambda_l1': trial.suggest_float('lambda_l1', 0, 10),\n",
        "              'lambda_l2': trial.suggest_float('lambda_l2', 0, 10),\n",
        "              'bagging_fraction':trial.suggest_uniform('bagging_fraction', 0, 1),\n",
        "              'bagging_freq':trial.suggest_int('bagging_freq',0,10),\n",
        "              'NUM_BOOST_ROUND': 200,\n",
        "              'EARLY_STOPPING_ROUNDS': 20,\n",
        "              'objective': 'rmse',\n",
        "              }\n",
        "    # Train the model and return the validation score\n",
        "    score = train_evaluate(params)\n",
        "    \n",
        "    #Check Pruning\n",
        "    trial.report(score,200)\n",
        "    if trial.should_prune():\n",
        "      raise optuna.TrialPruned()\n",
        "    \n",
        "    # Return the validation score\n",
        "    return score\n",
        "\n",
        "study4 = optuna.create_study(\n",
        "    direction = 'minimize',\n",
        "    sampler = optuna.samplers.TPESampler(),\n",
        "    pruner = optuna.pruners.HyperbandPruner()\n",
        "    )\n",
        "\n",
        "study4.optimize(objective, n_trials=N_TRIALS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJb6vlBEbabZ",
        "outputId": "8dff7631-c190-48df-bb4f-1d10f2b8031d"
      },
      "outputs": [],
      "source": [
        "bohbsearch = {'score': study4.best_value, 'params': study4.best_params}\n",
        "print(bohbsearch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "K8XEAc3JLzJs",
        "outputId": "53f04aa4-7877-4658-806e-4cd5d3ec3f59"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame([gridsearch['score'],randomsearch['score'],cmaessearch['score'],bohbsearch['score']],index=['Grid','Random','CMAES','BOHB'],columns=['RMSE'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8n9Xkv7bnM2"
      },
      "source": [
        "## Further Topics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbgu9CQ2r4UQ"
      },
      "source": [
        "### **Visualization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "iPlWe3oZbmrp",
        "outputId": "9b7c0c8f-af01-4025-a379-0e005d7b637a"
      },
      "outputs": [],
      "source": [
        "#History: \n",
        "trials_df = study4.trials_dataframe()\n",
        "trials_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "d8IXFo8CsTiU",
        "outputId": "6a9760e8-d24d-4e52-a8c5-d19fccfbdea6"
      },
      "outputs": [],
      "source": [
        "optuna.visualization.plot_optimization_history(study4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "jWUo_LcsvDHU",
        "outputId": "c69f977e-b9f1-4036-a0ca-c5817193f468"
      },
      "outputs": [],
      "source": [
        "optuna.visualization.plot_param_importances(study4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "ervzJ624sen1",
        "outputId": "6748540e-5c25-4b01-bc8b-da061bf46dc2"
      },
      "outputs": [],
      "source": [
        "optuna.visualization.plot_slice(study4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "bBd63INHs0-i",
        "outputId": "5d20e8e0-b522-44eb-88c8-ccd7231d1fee"
      },
      "outputs": [],
      "source": [
        "optuna.visualization.plot_parallel_coordinate(study4)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Practical_Hyperparameter_Optimization.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
